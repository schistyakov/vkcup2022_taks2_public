{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3048a4",
   "metadata": {
    "cellId": "dnrjj0oaw5s0dfku8ucrg8"
   },
   "outputs": [],
   "source": [
    "# %pip install pandas -U\n",
    "# %pip install numpy==1.20.3\n",
    "# %pip install pyarrow -U\n",
    "# %pip install tensorflow==2.11.0\n",
    "# %pip install tensorflow_ranking\n",
    "# %pip install tensorflow_recommenders\n",
    "# %pip install tensorflow_addons\n",
    "# %pip install tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ffe277",
   "metadata": {
    "cellId": "jj1c1m0zo7ayxe2c5lfq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:362: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:362: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "2023-01-17 06:34:07.981926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 06:34:24.564936: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-17 06:34:45.831715: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 06:34:45.832143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 06:34:45.832157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.__version__='1.20.3'\n",
      "pd.__version__='1.5.2'\n",
      "tf.__version__='2.11.0'\n",
      "tfr.__version__='0.5.1.dev'\n",
      "tfrs.__version__='v0.7.2'\n",
      "tfa.__version__='0.19.0'\n",
      "tfio.__version__='0.29.0'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from typing import Dict, Tuple, Text\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "print(f'{np.__version__=}')\n",
    "print(f'{pd.__version__=}')\n",
    "\n",
    "print(f'{tf.__version__=}')\n",
    "print(f'{tfr.__version__=}')\n",
    "print(f'{tfrs.__version__=}')\n",
    "print(f'{tfa.__version__=}')\n",
    "print(f'{tfio.__version__=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59434881",
   "metadata": {
    "cellId": "b1q2zwbqwrgvw7qp2b2ig"
   },
   "outputs": [],
   "source": [
    "CONFIG_TRAIN_DATA_PATH = '../data/train.parquet.gzip'\n",
    "CONFIG_TEST_DATA_PATH = '../data/test.parquet.gzip'\n",
    "CONFIG_META_DATA_PATH = '../data/items_meta.parquet.gzip'\n",
    "CONFIG_ITEMS_NEW_DATA_PATH = '../data/fresh_candidates.parquet.gzip'\n",
    "\n",
    "CONFIG_MODEL_CHECKPOINT_ROOT = '/home/jupyter/mnt/s3/vkcup2022/models'\n",
    "CONFIG_MODEL_REPORT_ROOT = '/home/jupyter/mnt/s3/vkcup2022/reports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ae87e2",
   "metadata": {
    "cellId": "ihzroonmvbcvbcipgtvqn"
   },
   "outputs": [],
   "source": [
    "def get_model_checkpoint_path_old(model_name: str) -> str:\n",
    "    model_checkpoin_path = os.path.join(CONFIG_MODEL_CHECKPOINT_ROOT, model_name, 'checkpoint')\n",
    "    print(f'get_model_checkpoint_path: {model_checkpoin_path}')\n",
    "    return model_checkpoin_path\n",
    "\n",
    "def get_model_checkpoint_path(model_name: str) -> str:\n",
    "    os.makedirs(CONFIG_MODEL_CHECKPOINT_ROOT, exist_ok=True)    \n",
    "    model_checkpoin_path = os.path.join(CONFIG_MODEL_CHECKPOINT_ROOT, model_name, '{epoch:02d}_checkpoint')\n",
    "    print(f'get_model_checkpoint_path: {model_checkpoin_path}')\n",
    "    return model_checkpoin_path\n",
    "\n",
    "def get_model_checkpoint_path_by_epoch(model_name: str, epoch: int) -> str:\n",
    "    model_checkpoin_path = os.path.join(CONFIG_MODEL_CHECKPOINT_ROOT, model_name, f'{epoch:02d}_checkpoint')\n",
    "    print(f'get_model_checkpoint_path_by_epoch: model_name={model_name} epoch={epoch} -> {model_checkpoin_path}')\n",
    "    return model_checkpoin_path\n",
    "\n",
    "def get_model_report_path(model_name: str) -> str:\n",
    "    os.makedirs(CONFIG_MODEL_REPORT_ROOT, exist_ok=True)\n",
    "    model_report_path = os.path.join(CONFIG_MODEL_REPORT_ROOT, f'{model_name}_report.csv')\n",
    "    print(f'get_model_report_path: {model_report_path}')\n",
    "    return model_report_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0ecd6",
   "metadata": {
    "cellId": "6nphfn637btd0wr2gtmpqv",
    "execution_id": "3107ff88-9ded-4841-8ec2-d37f35b9ce6c"
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9355ab31",
   "metadata": {
    "cellId": "4zyqj6bcr340zroe30i733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_count=1000183, item_id_count=227606, source_id_count=24438\n"
     ]
    }
   ],
   "source": [
    "user_id_count = 1000183\n",
    "item_id_count = 227606\n",
    "source_id_count = 24438\n",
    "print(f'{user_id_count=}, {item_id_count=}, {source_id_count=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a576b5",
   "metadata": {
    "cellId": "urf46a04gqobk3952kmi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_new_item_id: loading new item_id list from ../data/fresh_candidates.parquet.gzip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_new_item_id():\n",
    "    print(f'get_new_item_id: loading new item_id list from {CONFIG_ITEMS_NEW_DATA_PATH}')\n",
    "    item_id_new = pd.read_parquet(CONFIG_ITEMS_NEW_DATA_PATH).item_id.values\n",
    "    return item_id_new\n",
    "\n",
    "def get_new_item_id_dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(get_new_item_id()).map(lambda x: tf.cast(x, tf.int32))\n",
    "\n",
    "get_new_item_id().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a70055",
   "metadata": {
    "cellId": "fh9ttvlpr6t7ui1i4amtcu"
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, folder_path='dataloader_short'):\n",
    "        print(f'DataLoader:init:begin: {folder_path}')\n",
    "        self.folder_path=folder_path\n",
    "        \n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        self.train_train_data_file_path = os.path.join(folder_path, 'data_loader_train_train.parquet.gzip')\n",
    "        self.train_valid_data_file_path = os.path.join(folder_path, 'data_loader_train_valid.parquet.gzip')\n",
    "        self.test_data_file_path = os.path.join(folder_path, 'data_loader_test.parquet.gzip')\n",
    "        \n",
    "        self.train_train_item_id_history = os.path.join(folder_path, 'data_loader_train_train_item_id_history.npz')\n",
    "        self.train_valid_item_id_history = os.path.join(folder_path, 'data_loader_train_valid_item_id_history.npz')\n",
    "        self.test_item_id_history = os.path.join(folder_path, 'data_loader_test_item_id_history.npz')\n",
    "\n",
    "        self.train_train_timespent_history = os.path.join(folder_path, 'data_loader_train_train_timespent_history.npz')\n",
    "        self.train_valid_timespent_history = os.path.join(folder_path, 'data_loader_train_valid_timespent_history.npz')\n",
    "        self.test_timespent_history = os.path.join(folder_path, 'data_loader_test_timespent_history.npz')    \n",
    "        \n",
    "        print(f'DataLoader:init:end')\n",
    "                \n",
    "    def build(self):\n",
    "        print(f'DataLoader:prepare:begin')      \n",
    "                \n",
    "        print(f'loading train: {CONFIG_TRAIN_DATA_PATH}')\n",
    "        train = pd.read_parquet(CONFIG_TRAIN_DATA_PATH)\n",
    "        train['type'] = 0\n",
    "        \n",
    "        ###################################################################################\n",
    "        # Найдем выборку для теста. Это будут последние записи для пользователей, которых нет в тестовой выборке \n",
    "        train_valid_size = 8192 * 4\n",
    "        \n",
    "        user_id_all = np.arange(user_id_count)\n",
    "        user_id_new = get_new_item_id()\n",
    "        user_id_old = user_id_all[~np.isin(user_id_all,user_id_new)]\n",
    "\n",
    "        sample_size = train_valid_size\n",
    "        np.random.seed(1000)        \n",
    "        user_id_old_sample = np.random.choice(user_id_old, size=sample_size, replace=False)\n",
    "        print(f'Выбрали {user_id_old_sample.shape} пользователей для валидации')\n",
    "        \n",
    "        train_sample = train[['user_id']][(train.timespent > 0) & (train.user_id.isin(user_id_old_sample))]\n",
    "        print(f'unique = {train_sample.user_id.nunique()}')\n",
    "        \n",
    "        last_row_id_for_user_id_old_sample = np.array([i[-1] for i in train_sample.groupby('user_id').groups.values()])\n",
    "        print(f'Выбрали {last_row_id_for_user_id_old_sample.shape} идентификаторов строк для валидации')\n",
    "        train.loc[last_row_id_for_user_id_old_sample, 'type'] = 1 \n",
    "        del user_id_all, user_id_new, user_id_old, train_sample, last_row_id_for_user_id_old_sample\n",
    "        ###################################################################################        \n",
    "                \n",
    "        print(f'loading test: {CONFIG_TEST_DATA_PATH}')\n",
    "        test = pd.read_parquet(CONFIG_TEST_DATA_PATH)\n",
    "        test['item_id'] = -1\n",
    "        test['timespent'] = 1  \n",
    "        test['reaction'] = 0\n",
    "        test['type'] = 2\n",
    "        \n",
    "        data = pd.concat([train, test]).reset_index(drop=True)\n",
    "        del train, test     \n",
    "        \n",
    "        data_item_id_history, data_timespent_history = DataLoader.get_last_5_item_id(data)\n",
    "        \n",
    "        data = data[data.timespent > 0]\n",
    "        \n",
    "        train_train = data[data['type']==0].drop(columns=['type']).copy()\n",
    "        train_train_item_id_history = data_item_id_history[train_train.index.values]\n",
    "        train_train_timespent_history = data_timespent_history[train_train.index.values]        \n",
    "        \n",
    "        train_train.to_parquet(self.train_train_data_file_path, compression='gzip')\n",
    "        self.save_object(train_train_item_id_history, self.train_train_item_id_history)\n",
    "        self.save_object(train_train_timespent_history, self.train_train_timespent_history)\n",
    "        \n",
    "        train_valid = data[data['type']==1].drop(columns=['type']).copy()\n",
    "        train_valid_item_id_history = data_item_id_history[train_valid.index.values]\n",
    "        train_valid_timespent_history = data_timespent_history[train_valid.index.values] \n",
    "        \n",
    "        train_valid.to_parquet(self.train_valid_data_file_path, compression='gzip')\n",
    "        self.save_object(train_valid_item_id_history, self.train_valid_item_id_history)\n",
    "        self.save_object(train_valid_timespent_history, self.train_valid_timespent_history)\n",
    "        \n",
    "        test = data[data['type']==2].drop(columns=['item_id','timespent','reaction','type']).copy()\n",
    "        item_id_full_history = DataLoader.get_test_with_user_id_history()\n",
    "        test = test.merge(item_id_full_history, left_on='user_id', right_index=True)\n",
    "        \n",
    "        test_item_id_history = data_item_id_history[test.index.values]\n",
    "        test_timespent_history = data_timespent_history[test.index.values]  \n",
    "        \n",
    "        test.to_parquet(self.test_data_file_path, compression='gzip')\n",
    "        self.save_object(test_item_id_history, self.test_item_id_history)\n",
    "        self.save_object(test_timespent_history, self.test_timespent_history)\n",
    "    \n",
    "        print(f'DataLoader:prepare:end')       \n",
    "        \n",
    "\n",
    "        \n",
    "    def get_last_5_item_id(data, window = 5):\n",
    "        print(f'DataLoader:get_last_5_item_id:begin')                        \n",
    "        last_item_id_by_user_id = np.ones((user_id_count, window), dtype='int') * item_id_count\n",
    "        last_timespent_by_user_id = np.ones((user_id_count, window), dtype='int') * 1\n",
    "\n",
    "        last_item_id_result = np.zeros((len(data), window), dtype='int')\n",
    "        last_timespent_result = np.zeros((len(data), window), dtype='int')\n",
    "\n",
    "        for i, row in enumerate(data[['user_id','item_id','timespent']].itertuples(index=False)):\n",
    "            last_item_id_result[i,:] = last_item_id_by_user_id[row.user_id,:]\n",
    "            last_timespent_result[i,:] = last_timespent_by_user_id[row.user_id,:] \n",
    "\n",
    "            last_item_id_by_user_id[row.user_id, 0:window-1] = last_item_id_by_user_id[row.user_id, 1:window]\n",
    "            last_item_id_by_user_id[row.user_id, window-1] = row.item_id\n",
    "\n",
    "            last_timespent_by_user_id[row.user_id, 0:window-1] = last_timespent_by_user_id[row.user_id, 1:window]\n",
    "            last_timespent_by_user_id[row.user_id, window-1] = row.timespent               \n",
    "\n",
    "        print(f'DataLoader:get_last_5_item_id:end')                            \n",
    "        return last_item_id_result, last_timespent_result\n",
    "    \n",
    "    def get_test_with_user_id_history():\n",
    "        print(f'DataLoader:get_test_with_user_id_history:begin')                        \n",
    "        \n",
    "        print(f'Loading train data: {CONFIG_TRAIN_DATA_PATH}')    \n",
    "        train = pd.read_parquet(CONFIG_TRAIN_DATA_PATH, columns=['user_id', 'item_id'])\n",
    "        print(train.shape)\n",
    "        print(train.head())\n",
    "\n",
    "        print(f'Loading test data: {CONFIG_TEST_DATA_PATH}')\n",
    "        test = pd.read_parquet(CONFIG_TEST_DATA_PATH)\n",
    "        print(test.head())       \n",
    "        print(test.shape)\n",
    "\n",
    "        print('Filter train by test only users')\n",
    "        train = train[train.user_id.isin(test.user_id)]\n",
    "        print(train.head())    \n",
    "        print(train.shape)\n",
    "        del test\n",
    "\n",
    "        print('Group item history')\n",
    "        train = train.groupby('user_id').item_id.apply(list).to_frame('item_id_full_history')\n",
    "        print(train.head())    \n",
    "        print(train.shape)\n",
    "\n",
    "        print(f'DataLoader:get_test_with_user_id_history:end')                                \n",
    "        return train    \n",
    "    \n",
    "    def get_item_dataset_v2(df, item_id_history, timespent_history):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                'row_id':df.index,\n",
    "                'user_id':df.user_id,\n",
    "                'item_id':df.item_id,\n",
    "                'timespent':df.timespent,\n",
    "                'reaction':df.reaction + 1,\n",
    "                'item_id_history':item_id_history,\n",
    "                'timespent_history':timespent_history,            \n",
    "            })\n",
    "        return dataset\n",
    "    \n",
    "    def get_train_train_dataset_v4(self, batch_size):\n",
    "        print(f'DataLoader:get_train_train_dataset_v4:begin: {batch_size=}')        \n",
    "        #######################################################################       \n",
    "        print(f'DataLoader:get_train_train_dataset_v4: loading {self.train_train_data_file_path}')                \n",
    "        df = pd.read_parquet(self.train_train_data_file_path).astype(np.int32)        \n",
    "        item_id_history = self.load_object(self.train_train_item_id_history)\n",
    "        timespent_history = self.load_object(self.train_train_timespent_history)           \n",
    "        #######################################################################\n",
    "        np.random.seed(10)\n",
    "        i = np.arange(len(df))\n",
    "        np.random.shuffle(i)\n",
    "        df = df.iloc[i]\n",
    "        item_id_history = item_id_history[i,:]\n",
    "        timespent_history = timespent_history[i,:]        \n",
    "        #######################################################################        \n",
    "        print(f'DataLoader:get_train_train_dataset_v4:begin: {batch_size=}')\n",
    "        dataset = DataLoader.get_item_dataset_v2(df,item_id_history, timespent_history)\n",
    "        dataset = dataset.batch(batch_size*10)       \n",
    "        dataset = dataset.cache()    \n",
    "        dataset = dataset.unbatch()       \n",
    "        dataset = dataset.shuffle(batch_size*10)        \n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)       \n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)    \n",
    "        print('DataLoader:get_train_train_dataset_v4:end:')    \n",
    "        return dataset      \n",
    "\n",
    "    def get_train_valid_dataset_v2(self, batch_size):\n",
    "        print(f'DataLoader:get_train_valid_dataset_v2:begin: {batch_size=}')\n",
    "        #######################################################################\n",
    "        print(f'DataLoader:get_train_valid_dataset_v2: loading {self.train_valid_data_file_path}')                        \n",
    "        df = pd.read_parquet(self.train_valid_data_file_path).astype(np.int32)\n",
    "        item_id_history = self.load_object(self.train_valid_item_id_history)\n",
    "        timespent_history = self.load_object(self.train_valid_timespent_history)\n",
    "        #######################################################################\n",
    "        dataset = DataLoader.get_item_dataset_v2(df,item_id_history, timespent_history)\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)       \n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)    \n",
    "        print('DataLoader:get_train_valid_dataset_v2:end:')    \n",
    "        return dataset \n",
    "    \n",
    "    def get_test_dataframe(self):\n",
    "        return pd.read_parquet(self.test_data_file_path, columns=['user_id'])\n",
    "    \n",
    "    def get_test_dataframe_full(self):\n",
    "        return pd.read_parquet(self.test_data_file_path)    \n",
    "    \n",
    "    def get_test_dataset_v2(self, batch_size):\n",
    "        print(f'DataLoader:get_test_dataset_v2:begin: {batch_size=}')\n",
    "        #######################################################################\n",
    "        df = pd.read_parquet(self.test_data_file_path)\n",
    "        item_id_history = self.load_object(self.test_item_id_history)\n",
    "        timespent_history = self.load_object(self.test_timespent_history)        \n",
    "        #######################################################################            \n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                'user_id':df.user_id.astype(np.int32),\n",
    "                'item_id_history':item_id_history,\n",
    "                'timespent_history':timespent_history,\n",
    "            })    \n",
    "        dataset_item_id_full_history = tf.data.Dataset.from_generator(lambda: df.item_id_full_history, output_shapes=(None,), output_types=tf.int32)  \n",
    "\n",
    "        def fn_add_history(item1, item2):\n",
    "            item1['item_id_full_history'] = item2\n",
    "            return item1\n",
    "        dataset = tf.data.Dataset.zip((dataset, dataset_item_id_full_history)).map(fn_add_history)\n",
    "\n",
    "        dataset = dataset.padded_batch(batch_size, padding_values={'user_id':None, 'item_id_history':None, 'timespent_history':None, 'item_id_full_history':tf.constant(-1, dtype=tf.int32)})\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)    \n",
    "        print('DataLoader:get_test_dataset_v2:end:')    \n",
    "        return dataset     \n",
    "    \n",
    "    def get_test_dataset_final(self, predictions, batch_size):\n",
    "        print(f'DataLoader:get_test_dataset_final:begin: {batch_size=}')\n",
    "        #######################################################################\n",
    "        df = pd.read_parquet(self.test_data_file_path)\n",
    "        item_id_history = self.load_object(self.test_item_id_history)\n",
    "        timespent_history = self.load_object(self.test_timespent_history)              \n",
    "        #######################################################################            \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                'user_id':df.user_id.astype(np.int32),\n",
    "                'item_id_history':item_id_history,\n",
    "                'timespent_history':timespent_history,\n",
    "                'predictions':predictions,\n",
    "            })    \n",
    "\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)    \n",
    "        print('DataLoader:get_test_dataset_final:end:')    \n",
    "        return dataset    \n",
    "    \n",
    "    def get_test_level2_df(self, test_predictions):\n",
    "        print(f'DataLoader:get_test_level2_df:begin:')  \n",
    "        \n",
    "        df = pd.read_parquet(self.test_data_file_path).drop(columns=['item_id_full_history'])\n",
    "        df['item_id_history'] = self.load_object(self.test_item_id_history).tolist()\n",
    "        df['timespent_history'] = self.load_object(self.test_timespent_history).tolist()  \n",
    "        df = df.merge(test_predictions[['user_id', 'predictions']], on='user_id', how='left') \n",
    "        df = df.explode('predictions').rename(columns={'predictions':'item_id'})\n",
    "        \n",
    "        print(f'DataLoader:get_test_level2_df:end:')                \n",
    "        return df\n",
    "    \n",
    "    def get_test_dataset_level2(self, df, batch_size):\n",
    "        print(f'DataLoader:get_test_dataset_final:begin: {batch_size=}')        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                'user_id':df.user_id.astype(np.int32),\n",
    "                'item_id_history':tf.constant(df.item_id_history.tolist(), dtype=tf.int32),\n",
    "                'timespent_history':tf.constant(df.timespent_history.tolist(), dtype=tf.int32),\n",
    "                'item_id':df.item_id.astype(np.int32),\n",
    "            })    \n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "    \n",
    "    def save_object(self, obj, name):\n",
    "        print(f'DataLoader:save_object:begin: {name=} {obj.shape=}')                \n",
    "        np.savez_compressed(name, obj=obj)\n",
    "        print(f'DataLoader:save_object:end')        \n",
    "\n",
    "    def load_object(self, name):\n",
    "        print(f'DataLoader:load_object:begin: {name=}')        \n",
    "        loaded = np.load(name)\n",
    "        obj = loaded['obj']\n",
    "        print(f'DataLoader:load_object:end: {obj.shape=}')\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d683bb6",
   "metadata": {
    "cellId": "dhsv3hbrkkbzrrkq3dilko"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader:init:begin: dataloader_short\n",
      "DataLoader:init:end\n",
      "DataLoader:prepare:begin\n",
      "loading train: ../data/train.parquet.gzip\n",
      "get_new_item_id: loading new item_id list from ../data/fresh_candidates.parquet.gzip\n",
      "Выбрали (32768,) пользователей для валидации\n",
      "unique = 32768\n",
      "Выбрали (32768,) идентификаторов строк для валидации\n",
      "loading test: ../data/test.parquet.gzip\n",
      "DataLoader:get_last_5_item_id:begin\n",
      "DataLoader:get_last_5_item_id:end\n",
      "DataLoader:save_object:begin: name='dataloader_short/data_loader_train_train_item_id_history.npz' obj.shape=(23546702, 5)\n",
      "DataLoader:save_object:end\n",
      "DataLoader:save_object:begin: name='dataloader_short/data_loader_train_train_timespent_history.npz' obj.shape=(23546702, 5)\n",
      "DataLoader:save_object:end\n",
      "DataLoader:save_object:begin: name='dataloader_short/data_loader_train_valid_item_id_history.npz' obj.shape=(32768, 5)\n",
      "DataLoader:save_object:end\n",
      "DataLoader:save_object:begin: name='dataloader_short/data_loader_train_valid_timespent_history.npz' obj.shape=(32768, 5)\n",
      "DataLoader:save_object:end\n",
      "DataLoader:get_test_with_user_id_history:begin\n",
      "Loading train data: ../data/train.parquet.gzip\n",
      "(144440015, 2)\n",
      "   user_id  item_id\n",
      "0   707536    67950\n",
      "1   707536   151002\n",
      "2   707536   134736\n",
      "3   707536   196151\n",
      "4   707536    94182\n",
      "Loading test data: ../data/test.parquet.gzip\n",
      "   user_id\n",
      "0        7\n",
      "1        8\n",
      "2        9\n",
      "3       11\n",
      "4       18\n",
      "(200000, 1)\n",
      "Filter train by test only users\n",
      "    user_id  item_id\n",
      "18   534854   126856\n",
      "19   534854    30674\n",
      "20   699141   185459\n",
      "21   699141   199240\n",
      "22   699141    88313\n",
      "(32219777, 2)\n",
      "Group item history\n",
      "                                      item_id_full_history\n",
      "user_id                                                   \n",
      "7        [31519, 96533, 143250, 139289, 80095, 68034, 1...\n",
      "8        [54608, 35236, 132626, 122771, 74234, 97473, 1...\n",
      "9        [102264, 107480, 195650, 150185, 123898, 37165...\n",
      "11       [60476, 6950, 57464, 8807, 55361, 137764, 2110...\n",
      "18       [83206, 209961, 195887, 82423, 97456, 41394, 1...\n",
      "(200000, 1)\n",
      "DataLoader:get_test_with_user_id_history:end\n",
      "DataLoader:save_object:begin: name='dataloader_short/data_loader_test_item_id_history.npz' obj.shape=(200000, 5)\n",
      "DataLoader:save_object:end\n",
      "DataLoader:save_object:begin: name='dataloader_short/data_loader_test_timespent_history.npz' obj.shape=(200000, 5)\n",
      "DataLoader:save_object:end\n",
      "DataLoader:prepare:end\n"
     ]
    }
   ],
   "source": [
    "#!c1.8\n",
    "data_loader = DataLoader()\n",
    "data_loader.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69310ebc",
   "metadata": {
    "cellId": "3g6v4rnveq97m96hrmm1q3",
    "execution_id": "ff0991d2-2541-445d-ad53-4ea51fdd1199"
   },
   "source": [
    "# item_id mapping tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294638b8",
   "metadata": {
    "cellId": "1fr3k3o7kvisrlpg6js4km"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 06:47:34.364805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 06:47:35.292626: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-17 06:47:38.479623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 06:47:38.479958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 06:47:38.479971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col=neg bins=100\n",
      "col=neutral bins=10\n",
      "col=pos bins=100\n",
      "col=total bins=10\n",
      "col=neg_to_neutral bins=100\n",
      "col=pos_to_neutral bins=100\n",
      "col=pos_to_neg bins=100\n",
      "col=neutral_to_total bins=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 06:48:02.287459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 06:48:02.287498: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 00 col=neg bins=6 emdedding_dim=3\n",
      "feature 01 col=neutral bins=10 emdedding_dim=4\n",
      "feature 02 col=pos bins=21 emdedding_dim=6\n",
      "feature 03 col=total bins=10 emdedding_dim=4\n",
      "feature 04 col=neg_to_neutral bins=22 emdedding_dim=6\n",
      "feature 05 col=pos_to_neutral bins=62 emdedding_dim=9\n",
      "feature 06 col=pos_to_neg bins=27 emdedding_dim=6\n",
      "feature 07 col=neutral_to_total bins=20 emdedding_dim=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 43), dtype=float32, numpy=\n",
       "array([[-0.04321567,  0.03587705,  0.04728431,  0.01030605,  0.02305558,\n",
       "         0.00305545,  0.02268312, -0.01747249,  0.04319118,  0.00836311,\n",
       "         0.04466603,  0.03237144,  0.04549011,  0.02118548, -0.02938455,\n",
       "         0.04954486,  0.01419853,  0.03012474,  0.04294084, -0.03512242,\n",
       "         0.02964001,  0.04082492, -0.03886422, -0.02014476, -0.01179867,\n",
       "        -0.02099332,  0.01488617,  0.04309689,  0.02100218,  0.04251646,\n",
       "         0.02750904,  0.03333778,  0.00401454,  0.00462769,  0.01034806,\n",
       "        -0.03532853,  0.00644613, -0.00996416, -0.00771091,  0.00473355,\n",
       "         0.0455308 , -0.04618139, -0.04413335],\n",
       "       [-0.04321567,  0.03587705,  0.04728431,  0.02892549, -0.04102933,\n",
       "         0.03687557, -0.0270361 , -0.04344143, -0.04659208, -0.02863702,\n",
       "        -0.02531847, -0.03752828, -0.0367128 ,  0.00061371, -0.0255868 ,\n",
       "         0.00787774, -0.02393025,  0.03012474,  0.04294084, -0.03512242,\n",
       "         0.02964001,  0.04082492, -0.03886422,  0.01838035, -0.01830654,\n",
       "        -0.0046044 , -0.04090512,  0.00500679,  0.04323554, -0.02580338,\n",
       "         0.01831781, -0.00188553,  0.04798846,  0.03155868, -0.04755643,\n",
       "        -0.01388142, -0.03468152, -0.03070982,  0.0145298 ,  0.0301232 ,\n",
       "         0.00604318,  0.04635087, -0.01025902]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ItemsFeaturesModel:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        train = pd.read_parquet(CONFIG_TRAIN_DATA_PATH)\n",
    "        train_items_stat = train.groupby(['item_id','reaction']).size().unstack(level=1).fillna(0)\n",
    "        train_items_stat.columns = ['neg', 'neutral', 'pos']\n",
    "        train_items_stat['total'] = train_items_stat.sum(axis=1)\n",
    "        \n",
    "        train_items_stat['neg_to_neutral'] = (train_items_stat.neg / (train_items_stat.neutral + 1))\n",
    "        train_items_stat['pos_to_neutral'] = (train_items_stat.pos / (train_items_stat.neutral + 1))\n",
    "        train_items_stat['pos_to_neg'] = (train_items_stat.pos / (train_items_stat.neg + 1))\n",
    "        train_items_stat['neutral_to_total'] = (train_items_stat.neutral / (train_items_stat.total + 1))\n",
    "\n",
    "        params = {'neg':100,\n",
    "                  'neutral':10,\n",
    "                  'pos':100,\n",
    "                  'total':10,\n",
    "                  'neg_to_neutral':100,\n",
    "                  'pos_to_neutral':100,\n",
    "                  'pos_to_neg':100,\n",
    "                  'neutral_to_total':20,\n",
    "                 }\n",
    "        \n",
    "        bins_new = []\n",
    "        for col, bins in params.items():\n",
    "            print(f'col={col} bins={bins}')\n",
    "\n",
    "            train_items_stat[col] = pd.qcut(train_items_stat[col], q=bins, retbins=False, labels=False, duplicates='drop')\n",
    "            train_items_stat[col] = train_items_stat.groupby(col).ngroup()\n",
    "            bins_new.append(train_items_stat[col].nunique())            \n",
    "\n",
    "        self.item_id_features_map = tf.constant(train_items_stat.values, dtype=tf.int32)\n",
    "\n",
    "        item_id = tf.keras.layers.Input(name='item_id', dtype=tf.int32, shape=())\n",
    "        features_id_all = tf.keras.layers.Lambda(lambda x: tf.gather(self.item_id_features_map, x))(item_id)\n",
    "\n",
    "        embedding_list = []\n",
    "        for i, (col, bins) in enumerate(zip(params.keys(), bins_new)):\n",
    "            emdedding_dim = round(np.sqrt(bins))+1\n",
    "            print(f'feature {i:02} col={col} bins={bins} emdedding_dim={emdedding_dim}')\n",
    "            feature_id = features_id_all[:,i]\n",
    "            feature_embedding = tf.keras.layers.Embedding(bins, emdedding_dim)(feature_id)           \n",
    "            embedding_list.append(feature_embedding)\n",
    "            \n",
    "        features_embedding = tf.concat(embedding_list, axis=-1)\n",
    "#         x1 = tfrs.layers.dcn.Cross()(features_embedding, features_embedding)\n",
    "#         x2 = tfrs.layers.dcn.Cross()(features_embedding, x1)        \n",
    "#         features_embedding = x2\n",
    "        self.model = tf.keras.Model(inputs=item_id, outputs=features_embedding, name='get_item_id_stat_features')\n",
    "     \n",
    "    def __call__(self, features) -> tf.Tensor:\n",
    "        return self.model(features)\n",
    "\n",
    "ItemsFeaturesModel()(tf.constant([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b359e1c3",
   "metadata": {
    "cellId": "r3u2xnlqqcffn48fn6asp4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_content_embedding_by_item_id_mapping_table:begin:\n",
      "get_content_embedding_by_item_id_mapping_table:end:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(227607, 312)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_content_embedding_by_item_id_mapping_table():\n",
    "    print('get_content_embedding_by_item_id_mapping_table:begin:')\n",
    "    embedding_matrix = pd.read_parquet(CONFIG_META_DATA_PATH, columns=['embeddings'])\n",
    "    embedding_matrix = embedding_matrix.embeddings.tolist()\n",
    "    embedding_matrix = np.array(embedding_matrix)\n",
    "    embedding_matrix = np.vstack([embedding_matrix, np.mean(embedding_matrix,axis=0)])    \n",
    "    print('get_content_embedding_by_item_id_mapping_table:end:')    \n",
    "    return embedding_matrix\n",
    "\n",
    "get_content_embedding_by_item_id_mapping_table().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6624082b",
   "metadata": {
    "cellId": "7fs8n03jxckodfkpm671ug"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_source_id_by_item_id_mapping_table:begin:\n",
      "get_source_id_by_item_id_mapping_table:end:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7340,  6284, 12766, ..., 20249,  8163, 24438])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_source_id_by_item_id_mapping_table():\n",
    "    print('get_source_id_by_item_id_mapping_table:begin:')\n",
    "    source_id_by_item_id_mapping_table = pd.read_parquet(CONFIG_META_DATA_PATH, columns=['source_id']).source_id.values\n",
    "    source_id_by_item_id_mapping_table = np.append(source_id_by_item_id_mapping_table, source_id_count)\n",
    "    print('get_source_id_by_item_id_mapping_table:end:')\n",
    "    return source_id_by_item_id_mapping_table\n",
    "\n",
    "get_source_id_by_item_id_mapping_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b18baa0",
   "metadata": {
    "cellId": "w2emdlpd87pad0aaryioh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_probability_by_item_id_mapping_table:begin\n",
      "get_probability_by_item_id_mapping_table: df.shape=(144440015, 2)\n",
      "get_probability_by_item_id_mapping_table: df.shape=(23579470, 2)\n",
      "get_probability_by_item_id_mapping_table: probability_by_item_id_mapping_table.shape=(227606,)\n",
      "get_probability_by_item_id_mapping_table:end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.69639097e-07, 5.34363156e-06, 1.90843984e-06, ...,\n",
       "       1.69639097e-07, 1.69639097e-07, 5.00435336e-06])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item popularity\n",
    "def get_probability_by_item_id_mapping_table():\n",
    "    print(f'get_probability_by_item_id_mapping_table:begin')\n",
    "    df = pd.read_parquet(CONFIG_TRAIN_DATA_PATH, columns=['item_id', 'timespent'])\n",
    "    print(f'get_probability_by_item_id_mapping_table: {df.shape=}')\n",
    "    df = df[df.timespent > 0]\n",
    "    print(f'get_probability_by_item_id_mapping_table: {df.shape=}')\n",
    "    \n",
    "    probability_by_item_id_mapping_table = df[['item_id']].groupby('item_id').size().values\n",
    "    probability_by_item_id_mapping_table = probability_by_item_id_mapping_table / np.sum(probability_by_item_id_mapping_table)\n",
    "    print(f'get_probability_by_item_id_mapping_table: {probability_by_item_id_mapping_table.shape=}')\n",
    "\n",
    "    print(f'get_probability_by_item_id_mapping_table:end')\n",
    "    return probability_by_item_id_mapping_table\n",
    "\n",
    "get_probability_by_item_id_mapping_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e1f35",
   "metadata": {
    "cellId": "z4iiu9o87wog7tx635lkir",
    "execution_id": "1371378c-9076-4748-8606-0604e48d8089"
   },
   "source": [
    "# Learning rate schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd30e185",
   "metadata": {
    "cellId": "chei5oecn954e1yaryzvxp"
   },
   "outputs": [],
   "source": [
    "def plot_schedulers(schedulers, n_steps):\n",
    "    if not isinstance(schedulers, list):\n",
    "        schedulers = [schedulers]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[10, 3])\n",
    "    for scheduler in schedulers:\n",
    "        x = range(n_steps)\n",
    "        y = [scheduler(i).numpy() for i in x]\n",
    "        ax1.plot(x, y, label=scheduler.name)\n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Learning Rate')\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2.plot(x, y, label=scheduler.name)\n",
    "        ax2.set_xlabel('Step')\n",
    "        ax2.set_ylabel('Learning Rate')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08486837",
   "metadata": {
    "cellId": "vp37jalx5u56wseegbl04",
    "execution_id": "9460db59-fb2b-425a-8552-4ebe4f7ed8d0"
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "058e7528",
   "metadata": {
    "cellId": "b5fgo66zfsmtk8po1807mp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullModel:init_shared_layers:begin\n",
      "get_source_id_by_item_id_mapping_table:begin:\n",
      "get_source_id_by_item_id_mapping_table:end:\n",
      "get_content_embedding_by_item_id_mapping_table:begin:\n",
      "get_content_embedding_by_item_id_mapping_table:end:\n",
      "get_probability_by_item_id_mapping_table:begin\n",
      "get_probability_by_item_id_mapping_table: df.shape=(144440015, 2)\n",
      "get_probability_by_item_id_mapping_table: df.shape=(23579470, 2)\n",
      "get_probability_by_item_id_mapping_table: probability_by_item_id_mapping_table.shape=(227606,)\n",
      "get_probability_by_item_id_mapping_table:end\n",
      "col=neg bins=100\n",
      "col=neutral bins=10\n",
      "col=pos bins=100\n",
      "col=total bins=10\n",
      "col=neg_to_neutral bins=100\n",
      "col=pos_to_neutral bins=100\n",
      "col=pos_to_neg bins=100\n",
      "col=neutral_to_total bins=20\n",
      "feature 00 col=neg bins=6 emdedding_dim=3\n",
      "feature 01 col=neutral bins=10 emdedding_dim=4\n",
      "feature 02 col=pos bins=21 emdedding_dim=6\n",
      "feature 03 col=total bins=10 emdedding_dim=4\n",
      "feature 04 col=neg_to_neutral bins=22 emdedding_dim=6\n",
      "feature 05 col=pos_to_neutral bins=62 emdedding_dim=9\n",
      "feature 06 col=pos_to_neg bins=27 emdedding_dim=6\n",
      "feature 07 col=neutral_to_total bins=20 emdedding_dim=5\n",
      "FullModel:init_shared_layers:end\n",
      "FullModel:get_user_model:begin\n",
      "encoded_item_id_history_embedding_with_poistion_and_rating.shape=TensorShape([None, 5, 441])\n",
      "TextRetrievalModel:get_user_model:end\n",
      "FullModel:get_item_model:begin\n",
      "TextRetrievalModel:get_item_model:end\n",
      "FullModel:get_rating_model:begin\n",
      "FullModel:get_rating_model:end\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"user_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " timespent_history_input (Input  [(None, 5)]         0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " item_id_history_input (InputLa  [(None, 5)]         0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.greater (TFOpLambda)   (None, 5)            0           ['timespent_history_input[0][0]']\n",
      "                                                                                                  \n",
      " get_source_id (Lambda)         (None, 5)            0           ['item_id_history_input[0][0]']  \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 5)            0           ['tf.math.greater[0][0]']        \n",
      "                                                                                                  \n",
      " item_id_embedding (Embedding)  multiple             14566848    ['item_id_history_input[0][0]']  \n",
      "                                                                                                  \n",
      " source_id_embedding (Embedding  multiple            1564096     ['get_source_id[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " get_content_embedding (Lambda)  (None, 5, 312)      0           ['item_id_history_input[0][0]']  \n",
      "                                                                                                  \n",
      " timespent_flag (Embedding)     (None, 5, 1)         2           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 5)           0           ['timespent_history_input[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 5, 441)       0           ['item_id_embedding[0][0]',      \n",
      "                                                                  'source_id_embedding[0][0]',    \n",
      "                                                                  'get_content_embedding[0][0]',  \n",
      "                                                                  'timespent_flag[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.log (TFOpLambda)       (None, 5)            0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 5, 441)      0           ['tf.concat_2[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 5, 1)         0           ['tf.math.log[0][0]']            \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 5, 441)       0           ['tf.__operators__.add_1[0][0]', \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 5, 441)      2338182     ['multiply[0][0]',               \n",
      " dAttention)                                                      'multiply[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 441)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 5, 441)       0           ['multiply[0][0]',               \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 5, 441)      882         ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 5, 441)       0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5, 441)       194922      ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 5, 441)       0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 5, 441)       0           ['layer_normalization[0][0]',    \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " user_id (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 5, 441)      882         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " user_id_embedding (Embedding)  (None, 64)           64011776    ['user_id[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 441)         0           ['layer_normalization_1[0][0]']  \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 64)           0           ['user_id_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 505)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'reshape[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          129536      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256)         1024        ['dense_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 256)          0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          32896       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           8256        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,849,814\n",
      "Trainable params: 82,849,046\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"item_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " item_id (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " get_source_id (Lambda)         (None,)              0           ['item_id[0][0]']                \n",
      "                                                                                                  \n",
      " item_id_embedding (Embedding)  multiple             14566848    ['item_id[0][0]']                \n",
      "                                                                                                  \n",
      " source_id_embedding (Embedding  multiple            1564096     ['get_source_id[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " get_content_embedding (Lambda)  (None, 312)         0           ['item_id[0][0]']                \n",
      "                                                                                                  \n",
      " get_item_id_stat_features (Fun  (None, 43)          1176        ['item_id[0][0]']                \n",
      " ctional)                                                                                         \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| item_id (InputLayer)         [(None,)]            0           []                               |\n",
      "|                                                                                                |\n",
      "| lambda_1 (Lambda)            (None, 8)            0           []                               |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_8 (Sl  (None,)           0           []                               |\n",
      "| icingOpLambda)                                                                                 |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_9 (Sl  (None,)           0           []                               |\n",
      "| icingOpLambda)                                                                                 |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_10 (S  (None,)           0           []                               |\n",
      "| licingOpLambda)                                                                                |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_11 (S  (None,)           0           []                               |\n",
      "| licingOpLambda)                                                                                |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_12 (S  (None,)           0           []                               |\n",
      "| licingOpLambda)                                                                                |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_13 (S  (None,)           0           []                               |\n",
      "| licingOpLambda)                                                                                |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_14 (S  (None,)           0           []                               |\n",
      "| licingOpLambda)                                                                                |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_15 (S  (None,)           0           []                               |\n",
      "| licingOpLambda)                                                                                |\n",
      "|                                                                                                |\n",
      "| embedding_8 (Embedding)      (None, 3)            18          []                               |\n",
      "|                                                                                                |\n",
      "| embedding_9 (Embedding)      (None, 4)            40          []                               |\n",
      "|                                                                                                |\n",
      "| embedding_10 (Embedding)     (None, 6)            126         []                               |\n",
      "|                                                                                                |\n",
      "| embedding_11 (Embedding)     (None, 4)            40          []                               |\n",
      "|                                                                                                |\n",
      "| embedding_12 (Embedding)     (None, 6)            132         []                               |\n",
      "|                                                                                                |\n",
      "| embedding_13 (Embedding)     (None, 9)            558         []                               |\n",
      "|                                                                                                |\n",
      "| embedding_14 (Embedding)     (None, 6)            162         []                               |\n",
      "|                                                                                                |\n",
      "| embedding_15 (Embedding)     (None, 5)            100         []                               |\n",
      "|                                                                                                |\n",
      "| tf.concat_1 (TFOpLambda)     (None, 43)           0           []                               |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " tf.concat_3 (TFOpLambda)       (None, 483)          0           ['item_id_embedding[1][0]',      \n",
      "                                                                  'source_id_embedding[1][0]',    \n",
      "                                                                  'get_content_embedding[0][0]',  \n",
      "                                                                  'get_item_id_stat_features[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          61952       ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 128)          0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,202,840\n",
      "Trainable params: 16,202,584\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"rating_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " full_embedding_input (InputLay  [(None, 128)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           8256        ['full_embedding_input[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64)          256         ['dense_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 64)           0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 32)           2080        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32)          128         ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 32)           0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32)           0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " timespent (Dense)              (None, 1)            33          ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1)            0           ['timespent[0][0]']              \n",
      "                                                                                                  \n",
      " reaction (Dense)               (None, 3)            99          ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,852\n",
      "Trainable params: 10,660\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from RetrievalCustomReward import RetrievalCustomReward # Исправляем ограничения на минимальную вероятность item_id в выборке\n",
    "\n",
    "class FullModelMaskedZeros(tfrs.Model):\n",
    "    def __init__(self, \n",
    "                 user_id_embedding_dim,\n",
    "                 item_id_embedding_dim,\n",
    "                 source_id_embedding_dim, \n",
    "                 user_layer_sizes,\n",
    "                 item_layer_sizes,\n",
    "                 rating_layer_sizes,\n",
    "                 retrieval_weight=1., rating_loss_timespent_weight=1., rating_loss_reaction_weight=1.,\n",
    "                 softmax_temperature=None,\n",
    "                 remove_accidental_hits=False,\n",
    "                 num_hard_negatives=None,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.retrieval_weight = retrieval_weight\n",
    "        self.rating_loss_timespent_weight = rating_loss_timespent_weight\n",
    "        self.rating_loss_reaction_weight = rating_loss_reaction_weight\n",
    "        \n",
    "        self.user_id_embedding_dim = user_id_embedding_dim\n",
    "        self.item_id_embedding_dim = item_id_embedding_dim\n",
    "        self.source_id_embedding_dim = source_id_embedding_dim\n",
    "        self.content_id_embedding_dim = 312\n",
    "        \n",
    "        self.user_layer_sizes = user_layer_sizes\n",
    "        self.item_layer_sizes = item_layer_sizes\n",
    "        self.rating_layer_sizes = rating_layer_sizes\n",
    "                \n",
    "        # Define models\n",
    "        self.init_shared_layers()\n",
    "        self.user_model = self.get_user_model()\n",
    "        self.item_model = self.get_item_model()\n",
    "        self.rating_model = self.get_rating_model()\n",
    "\n",
    "        # Define tasks\n",
    "        item_id_dataset = tf.data.Dataset.range(item_id_count).map(lambda x: tf.cast(x, tf.int32))\n",
    "        self.retrieval_task = RetrievalCustomReward(\n",
    "            temperature = softmax_temperature,\n",
    "            remove_accidental_hits = remove_accidental_hits,\n",
    "            num_hard_negatives = num_hard_negatives,\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM),\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=item_id_dataset.batch(1024).map(self.item_model),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.rating_task_timespent: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "        self.rating_task_reaction: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=None\n",
    "        )\n",
    "                \n",
    "        self.loss_tracker_rating_loss_timespent = tf.keras.metrics.Mean(name=\"rating_loss_timespent\")\n",
    "        self.loss_tracker_rating_loss_reaction = tf.keras.metrics.Mean(name=\"rating_loss_reaction\")\n",
    "        self.loss_tracker_retrieval_loss = tf.keras.metrics.Mean(name=\"retrieval_loss\")\n",
    "        self.loss_tracker_regularization_loss = tf.keras.metrics.Mean(name=\"regularization_loss\")\n",
    "        self.loss_tracker_total_loss = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "            \n",
    "    def init_shared_layers(self):\n",
    "        print('FullModel:init_shared_layers:begin')       \n",
    "        \n",
    "        self.user_id_embedding_layer = tf.keras.layers.Embedding(\n",
    "            user_id_count+1,\n",
    "            self.user_id_embedding_dim,\n",
    "            name='user_id_embedding',\n",
    "        )\n",
    "        \n",
    "        self.item_id_embedding_layer = tf.keras.layers.Embedding(\n",
    "            item_id_count+1, \n",
    "            self.item_id_embedding_dim,\n",
    "            name='item_id_embedding',\n",
    "        )\n",
    "        \n",
    "        self.source_id_embedding_layer = tf.keras.layers.Embedding(\n",
    "            source_id_count+1,\n",
    "            self.source_id_embedding_dim,\n",
    "            name='source_id_embedding',\n",
    "        )\n",
    "        \n",
    "        self.source_id_by_item_id_mapping_table = tf.constant(get_source_id_by_item_id_mapping_table(), dtype=tf.int32)        \n",
    "        self.content_embedding_by_item_id_mapping_table = tf.constant(get_content_embedding_by_item_id_mapping_table(), dtype=tf.float32)\n",
    "        self.probability_by_item_id_mapping_table = tf.constant(get_probability_by_item_id_mapping_table(), dtype=tf.float32)\n",
    "\n",
    "        self.item_id_feature_model = ItemsFeaturesModel().model\n",
    "        print('FullModel:init_shared_layers:end') \n",
    "        \n",
    "    def get_user_model(self):\n",
    "        print('FullModel:get_user_model:begin')\n",
    "        \n",
    "        user_id_input = tf.keras.Input(shape=(), name='user_id', dtype=tf.int32) \n",
    "        item_id_history_input = tf.keras.Input(shape=(5,), name='item_id_history_input', dtype=tf.int32) \n",
    "        timespent_history_input = tf.keras.Input(shape=(5,), name='timespent_history_input', dtype=tf.float32) \n",
    "\n",
    "        # Encoding user_id\n",
    "        user_id_embedding = self.user_id_embedding_layer(user_id_input)\n",
    "        \n",
    "        # Encoding item history\n",
    "        item_id_history_embedding = self.item_id_embedding_layer(item_id_history_input) \n",
    "        source_id_history = tf.keras.layers.Lambda(lambda x: tf.gather(self.source_id_by_item_id_mapping_table, x), name='get_source_id')(item_id_history_input)        \n",
    "        source_id_history_embedding = self.source_id_embedding_layer(source_id_history)        \n",
    "        content_history_embedding = tf.keras.layers.Lambda(lambda x: tf.gather(self.content_embedding_by_item_id_mapping_table, x), name='get_content_embedding')(item_id_history_input)\n",
    "        timespent_flag_history_embedding = tf.keras.layers.Embedding(2, 1, name='timespent_flag')(tf.cast(timespent_history_input > 0, tf.int32)) # Embedding to show timespent > 0\n",
    "        \n",
    "        item_history_embedding = tf.concat(values=[item_id_history_embedding, source_id_history_embedding, content_history_embedding, timespent_flag_history_embedding], axis=-1)        \n",
    "                \n",
    "        # Create positional embedding.\n",
    "        sequence_length = 5\n",
    "        position_embedding_encoder = tf.keras.layers.Embedding(\n",
    "            input_dim=sequence_length,\n",
    "            output_dim=self.item_id_embedding_dim + self.source_id_embedding_dim + self.content_id_embedding_dim + 1,\n",
    "            name=\"position_embedding\",\n",
    "        )\n",
    "        \n",
    "        positions = tf.range(start=0, limit=sequence_length, delta=1)\n",
    "        encodded_positions = position_embedding_encoder(positions)\n",
    "        \n",
    "        # Retrieve sequence ratings to incorporate them into the encoding\n",
    "        timespent_history = tf.expand_dims(tf.math.log(timespent_history_input + 2), -1)\n",
    "                \n",
    "        # Add the positional encoding to the item_id encodings and multiply them by rating.\n",
    "        encoded_item_id_history_embedding_with_poistion_and_rating = tf.keras.layers.Multiply()(\n",
    "            [(item_history_embedding + encodded_positions), timespent_history]\n",
    "        ) \n",
    "        print(f'{encoded_item_id_history_embedding_with_poistion_and_rating.shape=}')\n",
    "        \n",
    "        dropout_rate = 0.1\n",
    "        num_heads = 3\n",
    "        \n",
    "        transformer_features = encoded_item_id_history_embedding_with_poistion_and_rating\n",
    "        other_features = user_id_embedding\n",
    "        \n",
    "        ############################################################################################\n",
    "        # Create a multi-headed attention layer.\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=transformer_features.shape[2], dropout=dropout_rate\n",
    "        )(transformer_features, transformer_features)\n",
    "\n",
    "        # Transformer block.\n",
    "        attention_output = tf.keras.layers.Dropout(dropout_rate)(attention_output)\n",
    "        x1 = tf.keras.layers.Add()([transformer_features, attention_output])\n",
    "        x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "        x2 = tf.keras.layers.LeakyReLU()(x1)\n",
    "        x2 = tf.keras.layers.Dense(units=x2.shape[-1])(x2)\n",
    "        x2 = tf.keras.layers.Dropout(dropout_rate)(x2)\n",
    "        transformer_features = tf.keras.layers.Add()([x1, x2])\n",
    "        transformer_features = tf.keras.layers.LayerNormalization()(transformer_features)\n",
    "        ############################################################################################\n",
    "#         features = tf.keras.layers.Flatten()(transformer_features) # Очень долго, надо попробовать если будет время        \n",
    "        features = tf.keras.layers.GlobalAveragePooling1D()(transformer_features)\n",
    "        ############################################################################################\n",
    "\n",
    "        # Included the other features.\n",
    "        if other_features is not None:\n",
    "            features = tf.keras.layers.concatenate(\n",
    "                [features, tf.keras.layers.Reshape([other_features.shape[-1]])(other_features)]\n",
    "            )\n",
    "            \n",
    "        # Fully-connected layers.            \n",
    "        for num_units in self.user_layer_sizes[:-1]:\n",
    "            features = tf.keras.layers.Dense(num_units)(features)\n",
    "            features = tf.keras.layers.BatchNormalization()(features)\n",
    "            features = tf.keras.layers.LeakyReLU()(features)\n",
    "            features = tf.keras.layers.Dropout(dropout_rate)(features)\n",
    "            \n",
    "        for num_units in self.user_layer_sizes[-1:]:\n",
    "            features = tf.keras.layers.Dense(num_units)(features)            \n",
    "\n",
    "        ############################################################################################\n",
    "\n",
    "        print('TextRetrievalModel:get_user_model:end')                \n",
    "        return tf.keras.Model(\n",
    "            inputs={\n",
    "                'user_id':user_id_input,\n",
    "                'item_id_history':item_id_history_input,\n",
    "                'timespent_history':timespent_history_input\n",
    "            },\n",
    "            outputs=features, name='user_model')    \n",
    "    \n",
    "    def get_item_model(self):\n",
    "        print('FullModel:get_item_model:begin')  \n",
    "        \n",
    "        dropout_rate = 0.1     \n",
    "        \n",
    "        item_id_input = tf.keras.Input(shape=(), name='item_id', dtype=tf.int32)   \n",
    "        item_id_embedding = self.item_id_embedding_layer(item_id_input)\n",
    "\n",
    "        source_id = tf.keras.layers.Lambda(lambda x: tf.gather(self.source_id_by_item_id_mapping_table, x), name='get_source_id')(item_id_input)\n",
    "        source_id_embedding = self.source_id_embedding_layer(source_id)\n",
    "\n",
    "        content_embedding = tf.keras.layers.Lambda(lambda x: tf.gather(self.content_embedding_by_item_id_mapping_table, x), name='get_content_embedding')(item_id_input)\n",
    "        \n",
    "        item_stat_embedding = self.item_id_feature_model(item_id_input) # item_stat_embedding\n",
    "        \n",
    "        features = tf.concat(values=[item_id_embedding, source_id_embedding, content_embedding, item_stat_embedding], axis=-1)\n",
    "        \n",
    "        # Fully-connected layers.\n",
    "        for num_units in self.item_layer_sizes[:-1]:\n",
    "            features = tf.keras.layers.Dense(num_units)(features)\n",
    "            features = tf.keras.layers.BatchNormalization()(features)\n",
    "            features = tf.keras.layers.LeakyReLU()(features)\n",
    "            features = tf.keras.layers.Dropout(dropout_rate)(features)\n",
    "            \n",
    "        for num_units in self.item_layer_sizes[-1:]:\n",
    "            features = tf.keras.layers.Dense(num_units)(features)\n",
    "        \n",
    "        print('TextRetrievalModel:get_item_model:end')                \n",
    "        return tf.keras.Model(inputs=item_id_input, outputs=features, name='item_model')\n",
    "    \n",
    "    def get_rating_model(self):\n",
    "        print('FullModel:get_rating_model:begin')        \n",
    "        full_embedding_input = tf.keras.Input(shape=(self.user_layer_sizes[-1] + self.item_layer_sizes[-1]), name='full_embedding_input', dtype=tf.float32)  \n",
    "        \n",
    "        dropout_rate = 0.1    \n",
    "        \n",
    "        features = full_embedding_input\n",
    "        \n",
    "        # Fully-connected layers.\n",
    "        for num_units in self.rating_layer_sizes:\n",
    "            features = tf.keras.layers.Dense(num_units)(features)\n",
    "            features = tf.keras.layers.BatchNormalization()(features)\n",
    "            features = tf.keras.layers.LeakyReLU()(features)\n",
    "            features = tf.keras.layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "        timespent = tf.keras.layers.Dense(1, activation='sigmoid', name='timespent')(features)\n",
    "        timespent = timespent * 60\n",
    "        \n",
    "        reaction = tf.keras.layers.Dense(3, activation='softmax', name='reaction')(features)\n",
    "        \n",
    "        print('FullModel:get_rating_model:end')        \n",
    "        return tf.keras.Model(inputs=full_embedding_input, outputs=[timespent, reaction], name='rating_model')    \n",
    "    \n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        user_embedding = self.user_model(features)\n",
    "        item_embedding = self.item_model(features[\"item_id\"])\n",
    "        \n",
    "        timespent_pred, reaction_pred = self.rating_model(tf.concat([user_embedding, item_embedding], axis=1))\n",
    "        return (user_embedding, item_embedding, timespent_pred, reaction_pred)         \n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        timespent, reaction, row_id = features.pop(\"timespent\"), features.pop(\"reaction\"), features.pop(\"row_id\")\n",
    "        user_embedding, item_embedding, timespent_pred, reaction_pred = self(features)\n",
    "        \n",
    "        history_weight = 0.5 + 0.5 * tf.cast(row_id, tf.float32) / 144440014.\n",
    "        \n",
    "        rating_loss_timespent = self.rating_task_timespent(\n",
    "            labels=timespent,\n",
    "            predictions=timespent_pred,\n",
    "            sample_weight=tf.expand_dims(history_weight, axis=-1),\n",
    "        )\n",
    "        \n",
    "        rating_loss_reaction = self.rating_task_reaction(\n",
    "            labels=reaction,\n",
    "            predictions=reaction_pred,\n",
    "            sample_weight=tf.expand_dims(history_weight, axis=-1),\n",
    "        ) \n",
    "\n",
    "        timespent_weight = tf.math.log1p(tf.cast(timespent, tf.float32))\n",
    "\n",
    "        retrieval_loss = self.retrieval_task(\n",
    "            query_embeddings=user_embedding,\n",
    "            candidate_embeddings=item_embedding, \n",
    "            candidate_ids=features['item_id'],\n",
    "            rewards=timespent,\n",
    "            compute_metrics=not training, \n",
    "            sample_weight = history_weight * timespent_weight,\n",
    "            candidate_sampling_probability=tf.gather(self.probability_by_item_id_mapping_table, features[\"item_id\"])\n",
    "        )\n",
    "        \n",
    "        return rating_loss_timespent, rating_loss_reaction, retrieval_loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            rating_loss_timespent, rating_loss_reaction, retrieval_loss = self.compute_loss(inputs, training=True)\n",
    "            regularization_loss = sum(self.losses)\n",
    "            total_loss = self.rating_loss_timespent_weight * rating_loss_timespent + self.rating_loss_reaction_weight * rating_loss_reaction + self.retrieval_weight * retrieval_loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        self.loss_tracker_rating_loss_timespent.update_state(rating_loss_timespent)        \n",
    "        self.loss_tracker_rating_loss_reaction.update_state(rating_loss_reaction)                \n",
    "        self.loss_tracker_retrieval_loss.update_state(retrieval_loss)        \n",
    "        self.loss_tracker_regularization_loss.update_state(regularization_loss)        \n",
    "        self.loss_tracker_total_loss.update_state(total_loss)            \n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, inputs):\n",
    "        rating_loss_timespent, rating_loss_reaction, retrieval_loss = self.compute_loss(inputs, training=False)\n",
    "        regularization_loss = sum(self.losses)\n",
    "        total_loss = self.rating_loss_timespent_weight * rating_loss_timespent + self.rating_loss_reaction_weight * rating_loss_reaction + self.retrieval_weight * retrieval_loss + regularization_loss\n",
    "        \n",
    "        self.loss_tracker_rating_loss_timespent.update_state(rating_loss_timespent)        \n",
    "        self.loss_tracker_rating_loss_reaction.update_state(rating_loss_reaction)                \n",
    "        self.loss_tracker_retrieval_loss.update_state(retrieval_loss)        \n",
    "        self.loss_tracker_regularization_loss.update_state(regularization_loss)        \n",
    "        self.loss_tracker_total_loss.update_state(total_loss)           \n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        return metrics\n",
    "    \n",
    "def check_model():\n",
    "    model = FullModelMaskedZeros(\n",
    "        user_id_embedding_dim=64,\n",
    "        item_id_embedding_dim=64,\n",
    "        source_id_embedding_dim=64,      \n",
    "        user_layer_sizes = [256, 128, 64], \n",
    "        item_layer_sizes = [128, 64],\n",
    "        rating_layer_sizes = [64, 32],\n",
    "        softmax_temperature=0.05,\n",
    "        remove_accidental_hits=True,\n",
    "        num_hard_negatives=None,\n",
    "        retrieval_weight=1., rating_loss_timespent_weight=100., rating_loss_reaction_weight=10.,                      \n",
    "    )  \n",
    "    \n",
    "    print(model.user_model.summary(expand_nested=True))\n",
    "    tf.keras.utils.plot_model(model.user_model, show_shapes=True, show_dtype=True, expand_nested=True, to_file='user_model.png')\n",
    "\n",
    "    print(model.item_model.summary(expand_nested=True))\n",
    "    tf.keras.utils.plot_model(model.item_model, show_shapes=True, show_dtype=True, expand_nested=True, to_file='item_model.png')\n",
    "    \n",
    "    print(model.rating_model.summary(expand_nested=True))\n",
    "    tf.keras.utils.plot_model(model.rating_model, show_shapes=True, show_dtype=True, expand_nested=True, to_file='rating_model.png')    \n",
    "\n",
    "check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ac2ba4c",
   "metadata": {
    "cellId": "722furifai867vc0h3i05e"
   },
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    return [\n",
    "        tf.keras.callbacks.CSVLogger(get_model_report_path(model_name)),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath = get_model_checkpoint_path(model_name),   \n",
    "            verbose=1,\n",
    "            save_best_only=False,\n",
    "            save_weights_only=True,\n",
    "            save_freq='epoch'),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_total_loss',\n",
    "            mode='min',\n",
    "            verbose=1,    \n",
    "            patience=4,\n",
    "            restore_best_weights=True),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a5257d",
   "metadata": {
    "cellId": "6cuox933t5anz7sk6slrvr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 10\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay([steps_per_epoch, steps_per_epoch*3, ], [1e-3, 1e-4, 1e-4])\n",
    "\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = schedule(step)\n",
    "wd = lambda: 0.1 * schedule(step)\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "plot_schedulers(schedule, steps_per_epoch * epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f80be18",
   "metadata": {
    "cellId": "7kbdtflhtmeb5nj8npy8u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cell scheduled. Waiting for foreground cells to finish commits\n",
      "Preparing g1.1 instance...\n",
      "g1.1 instance is ready, running task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 06:49:53.075177: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 06:49:59.649263: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 06:49:59.649747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 06:49:59.649762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullModel:init_shared_layers:begin\n",
      "get_source_id_by_item_id_mapping_table:begin:\n",
      "get_source_id_by_item_id_mapping_table:end:\n",
      "get_content_embedding_by_item_id_mapping_table:begin:\n",
      "get_content_embedding_by_item_id_mapping_table:end:\n",
      "get_probability_by_item_id_mapping_table:begin\n",
      "get_probability_by_item_id_mapping_table: df.shape=(144440015, 2)\n",
      "get_probability_by_item_id_mapping_table: df.shape=(23579470, 2)\n",
      "get_probability_by_item_id_mapping_table: probability_by_item_id_mapping_table.shape=(227606,)\n",
      "get_probability_by_item_id_mapping_table:end\n",
      "col=neg bins=100\n",
      "col=neutral bins=10\n",
      "col=pos bins=100\n",
      "col=total bins=10\n",
      "col=neg_to_neutral bins=100\n",
      "col=pos_to_neutral bins=100\n",
      "col=pos_to_neg bins=100\n",
      "col=neutral_to_total bins=20\n",
      "feature 00 col=neg bins=6 emdedding_dim=3\n",
      "feature 01 col=neutral bins=10 emdedding_dim=4\n",
      "feature 02 col=pos bins=21 emdedding_dim=6\n",
      "feature 03 col=total bins=10 emdedding_dim=4\n",
      "feature 04 col=neg_to_neutral bins=22 emdedding_dim=6\n",
      "feature 05 col=pos_to_neutral bins=62 emdedding_dim=9\n",
      "feature 06 col=pos_to_neg bins=27 emdedding_dim=6\n",
      "feature 07 col=neutral_to_total bins=20 emdedding_dim=5\n",
      "FullModel:init_shared_layers:end\n",
      "FullModel:get_user_model:begin\n",
      "encoded_item_id_history_embedding_with_poistion_and_rating.shape=TensorShape([None, 5, 441])\n",
      "TextRetrievalModel:get_user_model:end\n",
      "FullModel:get_item_model:begin\n",
      "TextRetrievalModel:get_item_model:end\n",
      "FullModel:get_rating_model:begin\n",
      "FullModel:get_rating_model:end\n",
      "WARNING:tensorflow:AutoGraph could not transform <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7faa4c70f820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7faa4c70f820>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7faa4c70f820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7faa4c70f820>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "DataLoader:get_train_train_dataset_v4:begin: batch_size=8192\n",
      "DataLoader:get_train_train_dataset_v4: loading dataloader_short/data_loader_train_train.parquet.gzip\n",
      "DataLoader:load_object:begin: name='dataloader_short/data_loader_train_train_item_id_history.npz'\n",
      "DataLoader:load_object:end: obj.shape=(23546702, 5)\n",
      "DataLoader:load_object:begin: name='dataloader_short/data_loader_train_train_timespent_history.npz'\n",
      "DataLoader:load_object:end: obj.shape=(23546702, 5)\n",
      "DataLoader:get_train_train_dataset_v4:begin: batch_size=8192\n",
      "DataLoader:get_train_train_dataset_v4:end:\n",
      "DataLoader:get_train_valid_dataset_v2:begin: batch_size=8192\n",
      "DataLoader:get_train_valid_dataset_v2: loading dataloader_short/data_loader_train_valid.parquet.gzip\n",
      "DataLoader:load_object:begin: name='dataloader_short/data_loader_train_valid_item_id_history.npz'\n",
      "DataLoader:load_object:end: obj.shape=(32768, 5)\n",
      "DataLoader:load_object:begin: name='dataloader_short/data_loader_train_valid_timespent_history.npz'\n",
      "DataLoader:load_object:end: obj.shape=(32768, 5)\n",
      "DataLoader:get_train_valid_dataset_v2:end:\n",
      "get_model_report_path: /home/jupyter/mnt/s3/vkcup2022/reports/user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix_report.csv\n",
      "get_model_checkpoint_path: /home/jupyter/mnt/s3/vkcup2022/models/user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix/{epoch:02d}_checkpoint\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method FullModelMaskedZeros.call of <__main__.FullModelMaskedZeros object at 0x7faadc10b940>> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <bound method FullModelMaskedZeros.call of <__main__.FullModelMaskedZeros object at 0x7faadc10b940>>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method FullModelMaskedZeros.call of <__main__.FullModelMaskedZeros object at 0x7faadc10b940>> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <bound method FullModelMaskedZeros.call of <__main__.FullModelMaskedZeros object at 0x7faadc10b940>>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2874/Unknown - 598s 195ms/step - rating_loss_timespent: 4.3830 - rating_loss_reaction: 0.1353 - retrieval_loss: 50220.6641 - regularization_loss: 0.0000e+00 - total_loss: 50794.3008 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - root_mean_squared_error: 2.4112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "\n",
      "Epoch 1: saving model to /home/jupyter/mnt/s3/vkcup2022/models/user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix/01_checkpoint\n",
      "2875/2875 [==============================] - 711s 234ms/step - rating_loss_timespent: 4.3830 - rating_loss_reaction: 0.1353 - retrieval_loss: 50220.6641 - regularization_loss: 0.0000e+00 - total_loss: 50794.3008 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - root_mean_squared_error: 2.4112 - val_rating_loss_timespent: 5.1635 - val_rating_loss_reaction: 0.1134 - val_retrieval_loss: 63191.9922 - val_regularization_loss: 0.0000e+00 - val_total_loss: 63821.7578 - val_factorized_top_k/top_1_categorical_accuracy: 0.0296 - val_factorized_top_k/top_5_categorical_accuracy: 0.1116 - val_factorized_top_k/top_10_categorical_accuracy: 0.1713 - val_factorized_top_k/top_50_categorical_accuracy: 0.3677 - val_factorized_top_k/top_100_categorical_accuracy: 0.4715 - val_root_mean_squared_error: 2.3503\n",
      "Epoch 2/3\n",
      "2874/2875 [============================>.] - ETA: 0s - rating_loss_timespent: 3.4690 - rating_loss_reaction: 0.1033 - retrieval_loss: 41716.3672 - regularization_loss: 0.0000e+00 - total_loss: 42166.5469 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - root_mean_squared_error: 2.1449\n",
      "Epoch 2: saving model to /home/jupyter/mnt/s3/vkcup2022/models/user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix/02_checkpoint\n",
      "2875/2875 [==============================] - 506s 176ms/step - rating_loss_timespent: 3.4690 - rating_loss_reaction: 0.1033 - retrieval_loss: 41716.3672 - regularization_loss: 0.0000e+00 - total_loss: 42166.5469 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - root_mean_squared_error: 2.1449 - val_rating_loss_timespent: 4.9336 - val_rating_loss_reaction: 0.1065 - val_retrieval_loss: 61436.9492 - val_regularization_loss: 0.0000e+00 - val_total_loss: 62036.8281 - val_factorized_top_k/top_1_categorical_accuracy: 0.0331 - val_factorized_top_k/top_5_categorical_accuracy: 0.1210 - val_factorized_top_k/top_10_categorical_accuracy: 0.1874 - val_factorized_top_k/top_50_categorical_accuracy: 0.3918 - val_factorized_top_k/top_100_categorical_accuracy: 0.5014 - val_root_mean_squared_error: 2.2973\n",
      "Epoch 3/3\n",
      "2874/2875 [============================>.] - ETA: 0s - rating_loss_timespent: 3.2700 - rating_loss_reaction: 0.0960 - retrieval_loss: 38550.8945 - regularization_loss: 0.0000e+00 - total_loss: 38973.9062 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - root_mean_squared_error: 2.0827\n",
      "Epoch 3: saving model to /home/jupyter/mnt/s3/vkcup2022/models/user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix/03_checkpoint\n",
      "2875/2875 [==============================] - 505s 176ms/step - rating_loss_timespent: 3.2700 - rating_loss_reaction: 0.0960 - retrieval_loss: 38550.8945 - regularization_loss: 0.0000e+00 - total_loss: 38973.9062 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - root_mean_squared_error: 2.0827 - val_rating_loss_timespent: 4.8560 - val_rating_loss_reaction: 0.1021 - val_retrieval_loss: 62043.9375 - val_regularization_loss: 0.0000e+00 - val_total_loss: 62631.6172 - val_factorized_top_k/top_1_categorical_accuracy: 0.0331 - val_factorized_top_k/top_5_categorical_accuracy: 0.1219 - val_factorized_top_k/top_10_categorical_accuracy: 0.1873 - val_factorized_top_k/top_50_categorical_accuracy: 0.3969 - val_factorized_top_k/top_100_categorical_accuracy: 0.5057 - val_root_mean_squared_error: 2.2793\n",
      "Task is done, waiting for foreground cells to finish...\n",
      "Merging task result to the state\n",
      "Cannot apply result: following variables are changed in this cell and need manual merge: lr, data_loader, wd, get_model_report_path, FullModelMaskedZeros, DataLoader, optimizer, RetrievalCustomReward, steps_per_epoch, get_new_item_id_dataset, schedule, ItemsFeaturesModel, step, get_model_checkpoint_path, epochs, plot_schedulers\n",
      "To apply changes run: %apply_state a1287d04-c45a-424b-8807-a07e0cad6b37/bt1b7e4rvk762dt19gdp"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "#pragma async\n",
    "\n",
    "model_name = 'user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix'\n",
    "batch_size = 8192\n",
    "\n",
    "epochs = 3\n",
    "steps_per_epoch = 2875\n",
    "\n",
    "###############################################################################\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay([steps_per_epoch, steps_per_epoch*3, ], [1e-3, 1e-4, 1e-4])\n",
    "\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = schedule(step)\n",
    "wd = lambda: 0.1 * schedule(step)\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "plot_schedulers(schedule, steps_per_epoch * epochs)\n",
    "###############################################################################\n",
    "\n",
    "def train_model():\n",
    "    model = FullModelMaskedZeros(\n",
    "        user_id_embedding_dim=64,\n",
    "        item_id_embedding_dim=64,\n",
    "        source_id_embedding_dim=64,      \n",
    "        user_layer_sizes = [256, 128, 64], \n",
    "        item_layer_sizes = [128, 64],\n",
    "        rating_layer_sizes = [64, 32],      \n",
    "        softmax_temperature=0.05,\n",
    "        remove_accidental_hits=True,\n",
    "        num_hard_negatives=None,\n",
    "        retrieval_weight=1., rating_loss_timespent_weight=100., rating_loss_reaction_weight=1000.,                \n",
    "    )    \n",
    "    \n",
    "    model.compile(optimizer=optimizer)    \n",
    "    model.fit(data_loader.get_train_train_dataset_v4(batch_size),\n",
    "              validation_data = data_loader.get_train_valid_dataset_v2(batch_size).cache(),\n",
    "              epochs=epochs,\n",
    "              callbacks = get_callbacks(model_name))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc026f",
   "metadata": {
    "cellId": "4pultkcmor6jufzpru0g2d",
    "execution_id": "26149cbd-d7c8-4113-a67a-bd0bcdfa636a"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93252502",
   "metadata": {
    "cellId": "hi70dqjedwrip8zo582g6h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_predict:begin\n",
      "process_predict: loading new item_id list from ../data/fresh_candidates.parquet.gzip\n",
      "<bound method NDFrame.head of        item_id\n",
      "0            0\n",
      "1            2\n",
      "2            5\n",
      "3            6\n",
      "4            7\n",
      "...        ...\n",
      "99995   227588\n",
      "99996   227591\n",
      "99997   227602\n",
      "99998   227603\n",
      "99999   227605\n",
      "\n",
      "[100000 rows x 1 columns]>\n",
      "(100000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 07:44:55.150839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 07:44:56.210384: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-17 07:44:59.813909: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 07:44:59.814302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 07:44:59.814315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_new_item_id: loading new item_id list from ../data/fresh_candidates.parquet.gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 07:45:06.909350: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-17 07:45:06.909386: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "process_predict: Loading model\n",
      "FullModel:init_shared_layers:begin\n",
      "get_source_id_by_item_id_mapping_table:begin:\n",
      "get_source_id_by_item_id_mapping_table:end:\n",
      "get_content_embedding_by_item_id_mapping_table:begin:\n",
      "get_content_embedding_by_item_id_mapping_table:end:\n",
      "get_probability_by_item_id_mapping_table:begin\n",
      "get_probability_by_item_id_mapping_table: df.shape=(144440015, 2)\n",
      "get_probability_by_item_id_mapping_table: df.shape=(23579470, 2)\n",
      "get_probability_by_item_id_mapping_table: probability_by_item_id_mapping_table.shape=(227606,)\n",
      "get_probability_by_item_id_mapping_table:end\n",
      "col=neg bins=100\n",
      "col=neutral bins=10\n",
      "col=pos bins=100\n",
      "col=total bins=10\n",
      "col=neg_to_neutral bins=100\n",
      "col=pos_to_neutral bins=100\n",
      "col=pos_to_neg bins=100\n",
      "col=neutral_to_total bins=20\n",
      "feature 00 col=neg bins=6 emdedding_dim=3\n",
      "feature 01 col=neutral bins=10 emdedding_dim=4\n",
      "feature 02 col=pos bins=21 emdedding_dim=6\n",
      "feature 03 col=total bins=10 emdedding_dim=4\n",
      "feature 04 col=neg_to_neutral bins=22 emdedding_dim=6\n",
      "feature 05 col=pos_to_neutral bins=62 emdedding_dim=9\n",
      "feature 06 col=pos_to_neg bins=27 emdedding_dim=6\n",
      "feature 07 col=neutral_to_total bins=20 emdedding_dim=5\n",
      "FullModel:init_shared_layers:end\n",
      "FullModel:get_user_model:begin\n",
      "encoded_item_id_history_embedding_with_poistion_and_rating.shape=TensorShape([None, 5, 441])\n",
      "TextRetrievalModel:get_user_model:end\n",
      "FullModel:get_item_model:begin\n",
      "TextRetrievalModel:get_item_model:end\n",
      "FullModel:get_rating_model:begin\n",
      "FullModel:get_rating_model:end\n",
      "WARNING:tensorflow:AutoGraph could not transform <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7f15dc08a5e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7f15dc08a5e0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7f15dc08a5e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function FullModelMaskedZeros.__init__.<locals>.<lambda> at 0x7f15dc08a5e0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "get_model_checkpoint_path_by_epoch: model_name=user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix epoch=3 -> /home/jupyter/mnt/s3/vkcup2022/models/user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix/03_checkpoint\n",
      "process_predict: Loading index\n",
      "process_predict: Prediction\n",
      "DataLoader:get_test_dataset_v2:begin: batch_size=1024\n",
      "DataLoader:load_object:begin: name='dataloader_short/data_loader_test_item_id_history.npz'\n",
      "DataLoader:load_object:end: obj.shape=(200000, 5)\n",
      "DataLoader:load_object:begin: name='dataloader_short/data_loader_test_timespent_history.npz'\n",
      "DataLoader:load_object:end: obj.shape=(200000, 5)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function DataLoader.get_test_dataset_v2.<locals>.fn_add_history at 0x7f15d46c8160> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function DataLoader.get_test_dataset_v2.<locals>.fn_add_history at 0x7f15d46c8160>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function DataLoader.get_test_dataset_v2.<locals>.fn_add_history at 0x7f15d46c8160> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function DataLoader.get_test_dataset_v2.<locals>.fn_add_history at 0x7f15d46c8160>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "DataLoader:get_test_dataset_v2:end:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82379857fd574289840792477dab72aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TopK.query_with_exclusions at 0x7f15d46c8280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TopK.query_with_exclusions at 0x7f15d46c8280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['item_id_full_history'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting results\n",
      "process_predict:end\n"
     ]
    }
   ],
   "source": [
    "model_name = 'user_id_vs_item_id_v82_att_AdamW_scheduler2_64_stat_flag_fix'\n",
    "epoch = 3\n",
    "\n",
    "model1_hist_size = 20\n",
    "\n",
    "def process_predict(model_name, epoch, model1_hist_size):\n",
    "    print('process_predict:begin')\n",
    "    \n",
    "    print(f'process_predict: loading new item_id list from {CONFIG_ITEMS_NEW_DATA_PATH}')\n",
    "    items_new = pd.read_parquet(CONFIG_ITEMS_NEW_DATA_PATH)\n",
    "    print(items_new.head)    \n",
    "    print(items_new.shape)\n",
    "    \n",
    "    item_id_new_dataset = tf.data.Dataset.from_tensor_slices(get_new_item_id()).map(lambda x: tf.cast(x, tf.int32))\n",
    "    \n",
    "    print(f'process_predict: Loading model')\n",
    "    model = FullModelMaskedZeros(\n",
    "        user_id_embedding_dim=64,\n",
    "        item_id_embedding_dim=64,\n",
    "        source_id_embedding_dim=64,      \n",
    "        user_layer_sizes = [256, 128, 64], \n",
    "        item_layer_sizes = [128, 64],\n",
    "        rating_layer_sizes = [64, 32],      \n",
    "        softmax_temperature=0.05,\n",
    "        remove_accidental_hits=True,\n",
    "        num_hard_negatives=None,\n",
    "        retrieval_weight=1., rating_loss_timespent_weight=100., rating_loss_reaction_weight=1000.,                \n",
    "    ) \n",
    "    model.load_weights(get_model_checkpoint_path_by_epoch(model_name, epoch=epoch))\n",
    "\n",
    "    print(f'process_predict: Loading index')    \n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=model1_hist_size)\n",
    "    index.index_from_dataset(tf.data.Dataset.zip((item_id_new_dataset.batch(128), item_id_new_dataset.batch(128).map(model.item_model))))\n",
    "    \n",
    "    print(f'process_predict: Prediction')\n",
    "    item_id_pred_full = []\n",
    "    for item in tqdm(data_loader.get_test_dataset_v2(1024)):\n",
    "        score, item_id_pred = index.query_with_exclusions(\n",
    "            queries=item,\n",
    "            exclusions=item['item_id_full_history'])\n",
    "        item_id_pred_full.append(item_id_pred.numpy())\n",
    "        \n",
    "    print('Collecting results')\n",
    "    item_id_pred_full = np.vstack(item_id_pred_full)\n",
    "\n",
    "    test = data_loader.get_test_dataframe()\n",
    "    test['predictions'] = item_id_pred_full.tolist()\n",
    "    \n",
    "    print('process_predict:end')    \n",
    "    return test\n",
    "\n",
    "test = process_predict(model_name, epoch, model1_hist_size)\n",
    "test[['user_id', 'predictions']].to_parquet(f'submit_{model_name}_{epoch}_hist.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee970c",
   "metadata": {
    "cellId": "s6m2obuygs0gjd7pgtjfs8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "f08ddf00-66a7-4852-a450-5eb69bc51cb5",
  "notebookPath": "vkcup2022_task2/vkcup2022_task2_public.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
